# Adversarial Robustness
### Adversarial Attack

Explaining and Harnessing Adversarial Examples, arXiv 2014. [[paper]](https://arxiv.org/abs/1412.6572)

Towards Evaluating the Robustness of Neural Networks, arXiv 2016. [[paper]](https://arxiv.org/abs/1608.04644)

Towards Deep Learning Models Resistant to Adversarial Attacks, ICLR 2018. [[paper]](https://arxiv.org/abs/1706.06083) [[code]](https://github.com/MadryLab/cifar10_challenge)

Boosting Adversarial Attacks with Momentum, CVPR 2018. [[paper]](https://arxiv.org/abs/1710.06081) [[code]](https://github.com/dongyp13/Non-Targeted-Adversarial-Attacks)

Square Attack: a query-efficient black-box adversarial attack via random search, ECCV 2020. [[paper]](https://arxiv.org/abs/1912.00049) [[code]](https://github.com/max-andr/square-attack)

Reliable evaluation of adversarial robustness with an ensemble of diverse parameter-free attacks, ICML 2020. [[paper]](https://arxiv.org/abs/2003.01690) [[code]](https://github.com/fra31/auto-attack)

### Adversarial Defense (Adversarial Training)

Towards Deep Learning Models Resistant to Adversarial Attacks, ICLR 2018. [[paper]](https://arxiv.org/abs/1706.06083) [[code]](https://github.com/MadryLab/cifar10_challenge)

Curriculum Adversarial Training, IJCAI 2018. [[paper]](https://arxiv.org/abs/1805.04807)

Adversarial Logit Pairing, arXiv 2018. [[paper]](https://arxiv.org/abs/1803.06373)

On the Convergence and Robustness of Adversarial Training, ICML 2019. [[paper]](https://arxiv.org/abs/2112.08304)

Theoretically Principled Trade-off between Robustness and Accuracy, ICML 2019. [[paper]](https://arxiv.org/abs/1901.08573) [[code]](https://github.com/yaodongyu/TRADES)

Adversarial Training for Free, NeurIPS 2019. [[paper]](https://arxiv.org/abs/1904.12843) [[code]](https://github.com/ashafahi/free_adv_train)

Fast is better than free: Revisiting adversarial training, ICLR 2020. [[paper]](https://arxiv.org/abs/2001.03994) [[code]](https://github.com/locuslab/fast_adversarial)

Improving Adversarial Robustness Requires Revisiting Misclassified Examples, ICLR 2020. [[paper]](https://openreview.net/pdf?id=rklOg6EFwS) [[code]](https://github.com/YisenWang/MART)

Attacks Which Do Not Kill Training Make Adversarial Learning Stronger, ICML 2020. [[paper]](https://arxiv.org/abs/2002.11242) [[code]](https://github.com/zjfheart/Friendly-Adversarial-Training)

Adversarial Weight Perturbation Helps Robust Generalization, NeurIPS 2020. [[paper]](https://arxiv.org/abs/2004.05884) [[code]](https://github.com/csdongxian/AWP)

Boosting Adversarial Training with Hypersphere Embedding, NeurIPS 2020. [[paper]](https://arxiv.org/abs/2002.08619) [[code]](https://github.com/ShawnXYang/AT_HE)

Geometry-aware Instance-reweighted Adversarial Training, ICLR 2021. [[paper]](https://arxiv.org/abs/2010.01736) [[code]](https://github.com/zjfheart/Geometry-aware-Instance-reweighted-Adversarial-Training)

Learnable Boundary Guided Adversarial Training, ICCV 2021. [[paper]](https://arxiv.org/abs/2011.11164) [[code]](https://github.com/dvlab-research/LBGAT)

### Robust Overfitting

On the Convergence and Robustness of Adversarial Training, ICML 2019. [[paper]](https://arxiv.org/abs/2112.08304)

Self-Adaptive Training: beyond Empirical Risk Minimization, NIPS 2020. [[paper]](https://arxiv.org/abs/2002.10319)  [[code]](https://github.com/LayneH/self-adaptive-training)

Overfitting in adversarially robust deep learning, ICML 2020. [[paper]](https://arxiv.org/abs/2002.11569) [[code]](https://github.com/locuslab/robust_overfitting)

Robust Overfitting may be mitigated by properly learned smoothening, ICLR 2021. [[paper]](https://openreview.net/forum?id=qZzy5urZw9) [[code]](https://github.com/VITA-Group/Alleviate-Robust-Overfitting)

Exploring Memorization in Adversarial Training, ICLR 2022. [[paper]](https://arxiv.org/abs/2106.01606) 


### Discussion

Adversarially Robust Generalization Requires More Data, NeurIPS 2018. [[paper]](https://arxiv.org/abs/1804.11285) 

Robustness May Be at Odds with Accuracy, ICLR 2019. [[paper]](https://arxiv.org/abs/1805.12152)

Adversarial Examples Are Not Bugs, They Are Features, NeurIPS 2019. [[paper]](https://arxiv.org/abs/1905.02175) [[code]](https://github.com/MadryLab/robustness)

Unlabeled Data Improves Adversarial Robustness, NeurIPS 2019. [[paper]](https://arxiv.org/abs/1905.13736) [[code]](https://github.com/yaircarmon/semisup-adv)

Do Adversarially Robust ImageNet Models Transfer Better? NeurIPS 2020. [[paper]](https://arxiv.org/abs/2007.08489) [[code]](https://github.com/MadryLab/robustness)

Bag of Tricks for Adversarial Training, ICLR 2021. [[paper]](https://arxiv.org/abs/2010.00467) [[code]](https://github.com/P2333/Bag-of-Tricks-for-AT)

